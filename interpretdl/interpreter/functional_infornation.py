import numpy as np

from tqdm import tqdm
from .abc_interpreter import InputGradientInterpreter
from ..data_processor.readers import images_transform_pipeline, preprocess_save_path
from ..data_processor.visualizer import explanation_to_vis, show_vis_explanation, save_image


class FunctionalInformationInterpreter(InputGradientInterpreter):
    """
    Functional Information Interpreter.

    For input gradient based interpreters, the target issue is generally the vanilla input gradient's noises.
    The basic idea of reducing the noises is to use different similar inputs to get the input gradients and 
    do the (weighted) average. 

    Functional Information method solves the problem of meaningless local variations in partial derivatives
    by adding input-correlations-awared sampled noise to the inputs multiple times and take the (correlations-awared weighted) average of the gradients.

    Functional Information method also solves the problem of generating random noise thats not dependent on the input features 
    (pixels for images, tokens for nlp), by instead generating input-correlations-awared noise (as mentioned before).

    Intuitivly, the Functional Information of the input with respect to a specific class, 
    is high if the model's output layer class specific entry is highly variates for purtubations (adding input-correlations-aware sampled noise) on this input,
    and is low if the model's output layer class specific entry is almost constant for purtubations on this input.

    Note, the Functional Information of the input with respect to a specific class, can be vary between diffrent classes.
    """

    def __init__(self, model: callable, device: str = 'gpu:0'):
        """

        Args:
            model (callable): A model with :py:func:`forward` and possibly :py:func:`backward` functions.
            device (str): The device used for running ``model``, options: ``"cpu"``, ``"gpu:0"``, ``"gpu:1"`` 
                etc.
        """

        InputGradientInterpreter.__init__(self, model, device)


    def interpret(self,
                  inputs: str or list(str) or np.ndarray,
                  labels: list or np.ndarray = None,
                  dataset : str or list(str) or np.ndarray,
                  dataset_labels : list or np.ndarray = None,

                  noise_amount: int = 0.1,
                  n_samples: int = 50,
                  split: int = 2,
                  gradient_of: str = 'probability',
                  resize_to: int = 224,
                  crop_to: int = None,
                  visual: bool = True,
                  save_path: str = None) -> np.ndarray:
        """The technical details of FuncInfo method are described as follows:
        The method generates ``n_samples`` input-correlations-aware noised inputs, with the noise scale of ``noise_amount``, and then computes 
        the gradients *w.r.t.* these input-correlations-aware noised inputs. The final explanation is (input-correlations-aware weighted) averaged gradients. 

        Args:
            inputs (str or list): The input image filepath or a list of filepaths or numpy array of read images.
            labels (list or np.ndarray, optional): The target labels to analyze. The number of labels should be equal 
                to the number of images. If None, the most likely label for each image will be used. Default: ``None``. 
            dataset (str or list): The whole dataset filepath or a list of filepaths or numpy array of read images.  
            dataset_labels (list or np.ndarray, optional): The target labels for the whole dataset. The number of labels should be equal 
                to the dataset size. If None, the labels is infered from the dataset's filepaths names. Default: ``None``. 
            correlation_matrices (str or list): 
            save_path_corr_mat (str, optional): The filepath(s) to save/load the calculated correlation matrices. If None, the matrices will not be saved. 
                Default: ``None``. The correlation matrices in this file is for sampling correlations-aware noise, 
                for a specific class and add it to the image. Default: file path that contains a np.identity(height * width) ``identity_filepath``, 
                since the number of features of an image are its height*width, and by diffult if not taking into accont the correlation between the pixles, 
                the correlation matrix to sample the noise from is the Identity matrix.
            noise_amount (int, optional): Noise level of added correlation-aware noise to the image. The final std of the correlation-aware Gaussian random noise 
                is ``noise_amount`` * ``correlation_matrices['{class}']`` . Default: ``0.1``.
            n_samples (int, optional): The number of new images generated by adding noise. Default: ``50``.
            split (int, optional): The number of splits. Default: ``2``.
            gradient_of (str, optional): compute the gradient of ['probability', 'logit' or 'loss']. Default: 
                ``'probability'``. FuncInfo uses probability for all tasks by default.
            resize_to (int, optional): Images will be rescaled with the shorter edge being ``resize_to``. Defaults to 
                ``224``.
            crop_to (int, optional): After resize, images will be center cropped to a square image with the size 
                ``crop_to``. If None, no crop will be performed. Defaults to ``None``.
            visual (bool, optional): Whether or not to visualize the processed image. Default: ``True``.
            save_path (str, optional): The filepath(s) to save the processed image(s). If None, the image will not be 
                saved. Default: ``None``.

        Returns:
            np.ndarray: the explanation result.
        """

        self.init_corr_mat(dataset, labels = dataset_labels , specific_classes = None, resize_to, crop_to, save_path = save_path_corr_mat, visual = False) # calculated only if this class has not been calculated before
        
        imgs, data = images_transform_pipeline(inputs, resize_to, crop_to)
        # print(imgs.shape, data.shape, imgs.dtype, data.dtype)  # (1, 224, 224, 3) (1, 3, 224, 224) uint8 float32

        assert len(data) == 1, "interpret each sample individually, it is optimized."

        self._build_predict_fn(gradient_of=gradient_of)

        # obtain the labels (and initialization).
        _, predicted_label, predicted_proba = self.predict_fn(data, labels)
        self.predicted_label = predicted_label
        self.predicted_proba = predicted_proba
        if labels is None:
            labels = predicted_label

        labels = np.array(labels).reshape((1, ))

        # SmoothGrad
        max_axis = tuple(np.arange(1, data.ndim))
        stds = noise_amount * (np.max(data, axis=max_axis) - np.min(data, axis=max_axis))

        data_noised = []
        for i in range(n_samples):
            noise = np.concatenate(
                [np.float32(np.random.normal(0.0, stds[j], (1, ) + tuple(d.shape))) for j, d in enumerate(data)])
            data_noised.append(data + noise)

        data_noised = np.concatenate(data_noised, axis=0)
        # print(data_i.shape, labels.shape)
        # print(data_noised.shape)  # n_samples, 3, 224, 224

        # splits, to avoid large GPU memory usage.
        if split > 1:
            chunk = n_samples // split
            gradient_chunks = []
            for i in range(split - 1):
                gradients_i, _, _ = self.predict_fn(data_noised[i * chunk:(i + 1) * chunk], np.repeat(labels, chunk))
                gradient_chunks.append(gradients_i)
            gradients_s, _, _ = self.predict_fn(data_noised[chunk * (split - 1):],
                                             np.repeat(labels, n_samples - chunk * (split - 1)))
            gradient_chunks.append(gradients_s)
            gradients = np.concatenate(gradient_chunks, axis=0)
        else:
            # one split.
            gradients, _, _ = self.predict_fn(data_noised, np.repeat(labels, n_samples))

        avg_gradients = np.mean(gradients, axis=0, keepdims=True)
        # visualize and save image.
        if save_path is None and not visual:
            # no need to visualize or save explanation results.
            pass
        else:
            save_path = preprocess_save_path(save_path, 1)
            # print(imgs[i].shape, avg_gradients[i].shape)
            vis_explanation = explanation_to_vis(imgs[i], np.abs(avg_gradients[0]).sum(0), style='overlay_grayscale')
            if visual:
                show_vis_explanation(vis_explanation)
            if save_path[i] is not None:
                save_image(save_path[i], vis_explanation)

        # intermediate results, for possible further usages.
        self.labels = labels

        return avg_gradients

    def init_corr_mat(self,
                    inputs, 
                    labels, 
                    specific_classes = None, 
                    resize_to: int = 224,
                    crop_to: int = None,
                    save_path = None, 
                    visual = False): 
        """
        The covariance matrix is a crucial component of our proposed explainability method. In order to explain an output class y, 
        the covariance matrix of that class \Sigma need to be estimated empirically.

        The technical details are described as follows:
        The method gets data inputs and labels, and then computes the inputs correlation matrix *w.r.t.* each class seperatly and saves to ``save_path``.
        If one want to estimate the correlation matries for specific classes, pass ``specific_labels``.
        
        The covariance matrix may impose heavy memory requirements (the size of the covariance matrix of d-dimensional feature vectors is d^2).
        In cases of high-dimensional feature vectors, we can partition the features into subsets and sample according to the sampling protocol discussed in Sec. 4.2. 
        Alternatively, one may partition the features into subsets and assume that each subset shares the same covariance matrix. 
        For example, partitioning the features of an image into three subsets, one for each color channel, 
        and assuming all color channels share the same covariance matrix, resulting in a nine times smaller memory usage.

        Lastly, correlation matrix is required to be a positive-definite matrix. In the case where some of the features are constant 
        (e.g., the top row in the MNIST dataset is always black), or when the dimension of the feature vectors is higher than the size of the examples of class y, 
        the correlation matrix will not be a positive-definite matrix. Hence, we suggest adding a small noise to the diagonal of every correlation matrix,
        which is a well-known practice to modify the matrix to be positive-definite.

        Args:
            inputs (str or list): The datasets image filepath or a list of filepaths or numpy array of read images.
            labels (list or np.ndarray, optional): The target labels of the inputs. The number of labels should be equal 
                to the number of images. If None, the labels are infered from the ``inputs`` filepaths names. Default: ``None``.
            specific_labels (list or np.ndarray, optional): The specific target labels to calculate the corr for.  
            If None, calculates the corr for all labels. Default: ``None``.    
            save_path (str, optional): The filepath(s) to save the correlation matrix(s). If None, the correlation matrix will not be 
                saved. Default: ``None``.
            visual (bool, optional): Whether or not to visualize a part of the correlation matrix. Default: ``False``.    

        Returns:
            np.ndarray: the correlation matries
        """

        imgs, data = images_transform_pipeline(inputs, resize_to, crop_to)
